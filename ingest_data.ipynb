{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "098c423d-8e12-4eba-a1b6-f99004c22ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama_stack_client==0.2.22 (from -r requirements.txt (line 3))\n",
      "  Downloading llama_stack_client-0.2.22-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting gradio[mcp] (from -r requirements.txt (line 2))\n",
      "  Downloading gradio-5.49.1-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/app-root/lib64/python3.12/site-packages (from llama_stack_client==0.2.22->-r requirements.txt (line 3)) (4.10.0)\n",
      "Requirement already satisfied: click in /opt/app-root/lib64/python3.12/site-packages (from llama_stack_client==0.2.22->-r requirements.txt (line 3)) (8.1.8)\n",
      "Collecting distro<2,>=1.7.0 (from llama_stack_client==0.2.22->-r requirements.txt (line 3))\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting fire (from llama_stack_client==0.2.22->-r requirements.txt (line 3))\n",
      "  Downloading fire-0.7.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/app-root/lib64/python3.12/site-packages (from llama_stack_client==0.2.22->-r requirements.txt (line 3)) (0.28.1)\n",
      "Requirement already satisfied: pandas in /opt/app-root/lib64/python3.12/site-packages (from llama_stack_client==0.2.22->-r requirements.txt (line 3)) (2.3.2)\n",
      "Requirement already satisfied: prompt-toolkit in /opt/app-root/lib64/python3.12/site-packages (from llama_stack_client==0.2.22->-r requirements.txt (line 3)) (3.0.52)\n",
      "Collecting pyaml (from llama_stack_client==0.2.22->-r requirements.txt (line 3))\n",
      "  Downloading pyaml-25.7.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/app-root/lib64/python3.12/site-packages (from llama_stack_client==0.2.22->-r requirements.txt (line 3)) (2.10.6)\n",
      "Requirement already satisfied: requests in /opt/app-root/lib64/python3.12/site-packages (from llama_stack_client==0.2.22->-r requirements.txt (line 3)) (2.32.5)\n",
      "Requirement already satisfied: rich in /opt/app-root/lib64/python3.12/site-packages (from llama_stack_client==0.2.22->-r requirements.txt (line 3)) (13.9.4)\n",
      "Requirement already satisfied: sniffio in /opt/app-root/lib64/python3.12/site-packages (from llama_stack_client==0.2.22->-r requirements.txt (line 3)) (1.3.1)\n",
      "Requirement already satisfied: termcolor in /opt/app-root/lib64/python3.12/site-packages (from llama_stack_client==0.2.22->-r requirements.txt (line 3)) (2.3.0)\n",
      "Requirement already satisfied: tqdm in /opt/app-root/lib64/python3.12/site-packages (from llama_stack_client==0.2.22->-r requirements.txt (line 3)) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /opt/app-root/lib64/python3.12/site-packages (from llama_stack_client==0.2.22->-r requirements.txt (line 3)) (4.15.0)\n",
      "Collecting aiofiles<25.0,>=22.0 (from gradio[mcp]->-r requirements.txt (line 2))\n",
      "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting brotli>=1.1.0 (from gradio[mcp]->-r requirements.txt (line 2))\n",
      "  Downloading brotli-1.2.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /opt/app-root/lib64/python3.12/site-packages (from gradio[mcp]->-r requirements.txt (line 2)) (0.116.1)\n",
      "Collecting ffmpy (from gradio[mcp]->-r requirements.txt (line 2))\n",
      "  Downloading ffmpy-1.0.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting gradio-client==1.13.3 (from gradio[mcp]->-r requirements.txt (line 2))\n",
      "  Downloading gradio_client-1.13.3-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting groovy~=0.1 (from gradio[mcp]->-r requirements.txt (line 2))\n",
      "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting huggingface-hub<2.0,>=0.33.5 (from gradio[mcp]->-r requirements.txt (line 2))\n",
      "  Downloading huggingface_hub-1.1.4-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: jinja2<4.0 in /opt/app-root/lib64/python3.12/site-packages (from gradio[mcp]->-r requirements.txt (line 2)) (3.1.6)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in /opt/app-root/lib64/python3.12/site-packages (from gradio[mcp]->-r requirements.txt (line 2)) (3.0.2)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in /opt/app-root/lib64/python3.12/site-packages (from gradio[mcp]->-r requirements.txt (line 2)) (2.3.3)\n",
      "Collecting orjson~=3.0 (from gradio[mcp]->-r requirements.txt (line 2))\n",
      "  Downloading orjson-3.11.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: packaging in /opt/app-root/lib64/python3.12/site-packages (from gradio[mcp]->-r requirements.txt (line 2)) (25.0)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in /opt/app-root/lib64/python3.12/site-packages (from gradio[mcp]->-r requirements.txt (line 2)) (11.3.0)\n",
      "Collecting pydub (from gradio[mcp]->-r requirements.txt (line 2))\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting python-multipart>=0.0.18 (from gradio[mcp]->-r requirements.txt (line 2))\n",
      "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in /opt/app-root/lib64/python3.12/site-packages (from gradio[mcp]->-r requirements.txt (line 2)) (6.0.2)\n",
      "Collecting ruff>=0.9.3 (from gradio[mcp]->-r requirements.txt (line 2))\n",
      "  Downloading ruff-0.14.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
      "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio[mcp]->-r requirements.txt (line 2))\n",
      "  Downloading safehttpx-0.1.7-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio[mcp]->-r requirements.txt (line 2))\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in /opt/app-root/lib64/python3.12/site-packages (from gradio[mcp]->-r requirements.txt (line 2)) (0.47.3)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /opt/app-root/lib64/python3.12/site-packages (from gradio[mcp]->-r requirements.txt (line 2)) (0.13.3)\n",
      "Collecting typer<1.0,>=0.12 (from gradio[mcp]->-r requirements.txt (line 2))\n",
      "  Downloading typer-0.20.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /opt/app-root/lib64/python3.12/site-packages (from gradio[mcp]->-r requirements.txt (line 2)) (0.34.0)\n",
      "Collecting mcp==1.10.1 (from gradio[mcp]->-r requirements.txt (line 2))\n",
      "  Downloading mcp-1.10.1-py3-none-any.whl.metadata (40 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from llama_stack_client==0.2.22->-r requirements.txt (line 3))\n",
      "  Downloading pydantic-2.11.10-py3-none-any.whl.metadata (68 kB)\n",
      "Requirement already satisfied: fsspec in /opt/app-root/lib64/python3.12/site-packages (from gradio-client==1.13.3->gradio[mcp]->-r requirements.txt (line 2)) (2025.9.0)\n",
      "Requirement already satisfied: websockets<16.0,>=13.0 in /opt/app-root/lib64/python3.12/site-packages (from gradio-client==1.13.3->gradio[mcp]->-r requirements.txt (line 2)) (15.0.1)\n",
      "Collecting httpx-sse>=0.4 (from mcp==1.10.1->gradio[mcp]->-r requirements.txt (line 2))\n",
      "  Downloading httpx_sse-0.4.3-py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: jsonschema>=4.20.0 in /opt/app-root/lib64/python3.12/site-packages (from mcp==1.10.1->gradio[mcp]->-r requirements.txt (line 2)) (4.25.1)\n",
      "Collecting pydantic-settings>=2.5.2 (from mcp==1.10.1->gradio[mcp]->-r requirements.txt (line 2))\n",
      "  Downloading pydantic_settings-2.12.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting sse-starlette>=1.6.1 (from mcp==1.10.1->gradio[mcp]->-r requirements.txt (line 2))\n",
      "  Downloading sse_starlette-3.0.3-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/app-root/lib64/python3.12/site-packages (from anyio<5,>=3.5.0->llama_stack_client==0.2.22->-r requirements.txt (line 3)) (3.10)\n",
      "Requirement already satisfied: certifi in /opt/app-root/lib64/python3.12/site-packages (from httpx<1,>=0.23.0->llama_stack_client==0.2.22->-r requirements.txt (line 3)) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/app-root/lib64/python3.12/site-packages (from httpx<1,>=0.23.0->llama_stack_client==0.2.22->-r requirements.txt (line 3)) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/app-root/lib64/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->llama_stack_client==0.2.22->-r requirements.txt (line 3)) (0.16.0)\n",
      "Requirement already satisfied: filelock in /opt/app-root/lib64/python3.12/site-packages (from huggingface-hub<2.0,>=0.33.5->gradio[mcp]->-r requirements.txt (line 2)) (3.19.1)\n",
      "Collecting hf-xet<2.0.0,>=1.2.0 (from huggingface-hub<2.0,>=0.33.5->gradio[mcp]->-r requirements.txt (line 2))\n",
      "  Downloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting shellingham (from huggingface-hub<2.0,>=0.33.5->gradio[mcp]->-r requirements.txt (line 2))\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting typer-slim (from huggingface-hub<2.0,>=0.33.5->gradio[mcp]->-r requirements.txt (line 2))\n",
      "  Downloading typer_slim-0.20.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/app-root/lib64/python3.12/site-packages (from pandas->llama_stack_client==0.2.22->-r requirements.txt (line 3)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/app-root/lib64/python3.12/site-packages (from pandas->llama_stack_client==0.2.22->-r requirements.txt (line 3)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/app-root/lib64/python3.12/site-packages (from pandas->llama_stack_client==0.2.22->-r requirements.txt (line 3)) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/app-root/lib64/python3.12/site-packages (from pydantic<3,>=1.9.0->llama_stack_client==0.2.22->-r requirements.txt (line 3)) (0.7.0)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<3,>=1.9.0->llama_stack_client==0.2.22->-r requirements.txt (line 3))\n",
      "  Downloading pydantic_core-2.33.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3,>=1.9.0->llama_stack_client==0.2.22->-r requirements.txt (line 3))\n",
      "  Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/app-root/lib64/python3.12/site-packages (from rich->llama_stack_client==0.2.22->-r requirements.txt (line 3)) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/app-root/lib64/python3.12/site-packages (from rich->llama_stack_client==0.2.22->-r requirements.txt (line 3)) (2.19.2)\n",
      "Requirement already satisfied: wcwidth in /opt/app-root/lib64/python3.12/site-packages (from prompt-toolkit->llama_stack_client==0.2.22->-r requirements.txt (line 3)) (0.2.13)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/app-root/lib64/python3.12/site-packages (from requests->llama_stack_client==0.2.22->-r requirements.txt (line 3)) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/app-root/lib64/python3.12/site-packages (from requests->llama_stack_client==0.2.22->-r requirements.txt (line 3)) (1.26.20)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/app-root/lib64/python3.12/site-packages (from jsonschema>=4.20.0->mcp==1.10.1->gradio[mcp]->-r requirements.txt (line 2)) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/app-root/lib64/python3.12/site-packages (from jsonschema>=4.20.0->mcp==1.10.1->gradio[mcp]->-r requirements.txt (line 2)) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/app-root/lib64/python3.12/site-packages (from jsonschema>=4.20.0->mcp==1.10.1->gradio[mcp]->-r requirements.txt (line 2)) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/app-root/lib64/python3.12/site-packages (from jsonschema>=4.20.0->mcp==1.10.1->gradio[mcp]->-r requirements.txt (line 2)) (0.27.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/app-root/lib64/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->llama_stack_client==0.2.22->-r requirements.txt (line 3)) (0.1.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /opt/app-root/lib64/python3.12/site-packages (from pydantic-settings>=2.5.2->mcp==1.10.1->gradio[mcp]->-r requirements.txt (line 2)) (1.1.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/app-root/lib64/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->llama_stack_client==0.2.22->-r requirements.txt (line 3)) (1.17.0)\n",
      "Downloading llama_stack_client-0.2.22-py3-none-any.whl (369 kB)\n",
      "Downloading gradio_client-1.13.3-py3-none-any.whl (325 kB)\n",
      "Downloading mcp-1.10.1-py3-none-any.whl (150 kB)\n",
      "Downloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
      "Downloading brotli-1.2.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m477.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
      "Downloading huggingface_hub-1.1.4-py3-none-any.whl (515 kB)\n",
      "Downloading orjson-3.11.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (136 kB)\n",
      "Downloading pydantic-2.11.10-py3-none-any.whl (444 kB)\n",
      "Downloading pydantic_core-2.33.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m446.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Downloading ruff-0.14.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m128.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safehttpx-0.1.7-py3-none-any.whl (9.0 kB)\n",
      "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Downloading typer-0.20.0-py3-none-any.whl (47 kB)\n",
      "Downloading ffmpy-1.0.0-py3-none-any.whl (5.6 kB)\n",
      "Downloading fire-0.7.1-py3-none-any.whl (115 kB)\n",
      "Downloading gradio-5.49.1-py3-none-any.whl (63.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.5/63.5 MB\u001b[0m \u001b[31m194.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyaml-25.7.0-py3-none-any.whl (26 kB)\n",
      "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Downloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m252.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpx_sse-0.4.3-py3-none-any.whl (9.0 kB)\n",
      "Downloading pydantic_settings-2.12.0-py3-none-any.whl (51 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading sse_starlette-3.0.3-py3-none-any.whl (11 kB)\n",
      "Downloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Downloading typer_slim-0.20.0-py3-none-any.whl (47 kB)\n",
      "Installing collected packages: pydub, brotli, typing-inspection, typer-slim, shellingham, semantic-version, ruff, python-multipart, pydantic-core, pyaml, orjson, httpx-sse, hf-xet, groovy, fire, ffmpy, distro, aiofiles, sse-starlette, pydantic, typer, safehttpx, pydantic-settings, llama_stack_client, huggingface-hub, mcp, gradio-client, gradio\n",
      "  Attempting uninstall: pydantic-core\n",
      "    Found existing installation: pydantic_core 2.27.2\n",
      "    Uninstalling pydantic_core-2.27.2:\n",
      "      Successfully uninstalled pydantic_core-2.27.2\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 2.10.6\n",
      "    Uninstalling pydantic-2.10.6:\n",
      "      Successfully uninstalled pydantic-2.10.6\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "feast 0.53.0 requires pydantic==2.10.6, but you have pydantic 2.11.10 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed aiofiles-24.1.0 brotli-1.2.0 distro-1.9.0 ffmpy-1.0.0 fire-0.7.1 gradio-5.49.1 gradio-client-1.13.3 groovy-0.1.2 hf-xet-1.2.0 httpx-sse-0.4.3 huggingface-hub-1.1.4 llama_stack_client-0.2.22 mcp-1.10.1 orjson-3.11.4 pyaml-25.7.0 pydantic-2.11.10 pydantic-core-2.33.2 pydantic-settings-2.12.0 pydub-0.25.1 python-multipart-0.0.20 ruff-0.14.4 safehttpx-0.1.7 semantic-version-2.10.0 shellingham-1.5.4 sse-starlette-3.0.3 typer-0.20.0 typer-slim-0.20.0 typing-inspection-0.4.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3dba2543-c7d6-45fe-a99c-a5a0e4d8967f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "from llama_stack_client import LlamaStackClient, RAGDocument\n",
    "import pandas as pd\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a0a6057-be45-48b0-8800-bff0772f488b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Connected to Llama Stack server\n"
     ]
    }
   ],
   "source": [
    "sys.path.append('..')\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(\"INFO\")\n",
    "\n",
    "# Initialize the Llama Stack client\n",
    "client = LlamaStackClient(\n",
    "    #base_url=os.getenv(\"LLAMA_STACK_SERVER_URL\", \"http://llamastack-server.rh-proposal-ai.svc.cluster.local:8321\")\n",
    "    base_url=os.getenv(\"LLAMA_STACK_SERVER_URL\", \"http://llama-stack-milvus-remote-service.rh-proposal-ai.svc.cluster.local:8321\")\n",
    ")\n",
    "\n",
    "file_path = \"data/Commercial-Direct-LATAM-USD-Q3-2025-Subscriptions.csv\"\n",
    "vector_db_skus_name = \"skus_rh_vector_db\"\n",
    "vector_db_ocp_name = \"ocp_rh_vector_db\"\n",
    "\n",
    "logger.info(\"Connected to Llama Stack server\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1fd8d36e-78ea-424d-a905-584d4c9d2d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Preparing documents from data/Commercial-Direct-LATAM-USD-Q3-2025-Subscriptions.csv...\n",
      "INFO:__main__:Prepared 680 documents.\n"
     ]
    }
   ],
   "source": [
    "logger.info(f\"Preparing documents from {file_path}...\")\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "df.fillna('', inplace=True)\n",
    "\n",
    "# Get the list of columns in the DataFrame\n",
    "documents = []\n",
    "for index, row in df.iterrows():\n",
    "    # Combine relevant columns into the document's content/text\n",
    "    # This is what the embedding model will primarily \"read\"\n",
    "    text_content = (\n",
    "        f\"Year: {row['YEAR']}. Quarter: {row['QUARTER']}. SKU: {row['SKU']}. SKU Description: {row['SKU_Description']}. Product: {row['Product']}. Currency: {row['Currency']}. List Price: ${row['List_Price']}. Unit of Measure: {row['Unit_of_Measure']}. Cores: {row['Cores']}. Nodes: {row['Nodes']}. Sockets: {row['Sockets']}. Virtual Guests: {row['Virtual_Guests']}. Support Level: {row['Support_Level']}. Support Type: {row['Support_Type']}. Category: {row['Category']}. Region: {row['Region']}. Country: {row['Country']}. Service Term: {row['Service_Term']}.\"\n",
    "    )\n",
    "\n",
    "    # Include all original CSV columns as metadata\n",
    "    # This metadata can be used for filtering during retrieval or just for context\n",
    "    metadata = row.to_dict()\n",
    "\n",
    "    logger.debug(f\"Processing document {index + 1}: {text_content}...\")\n",
    "\n",
    "    # Create document object to ingest\n",
    "    documents.append(\n",
    "        RAGDocument(\n",
    "            # Use the index or a unique identifier\n",
    "            document_id=str(index) + \"-SKU-RH-LATAM-Q3-2025\",\n",
    "            # Assuming the content is plain text\n",
    "            mime_type=\"text/plain\",\n",
    "            # 'content' is the field for the main text\n",
    "            content=text_content,\n",
    "            metadata=metadata\n",
    "        )\n",
    "    )\n",
    "\n",
    "logger.info(f\"Prepared {len(documents)} documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "146edca2-cfef-47c1-b305-bd88404d24df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Preparing documents from URLs...\n",
      "INFO:__main__:Prepared 1 documents from URLs.\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Preparing documents from URLs...\")\n",
    "\n",
    "# ingest the documents into the newly created document collection\n",
    "urls = [\n",
    "    (\"https://www.openshift.guide/openshift-guide-screen.pdf\", \"application/pdf\"),\n",
    "]\n",
    "\n",
    "# Create document object to ingest\n",
    "documents_ocp = [\n",
    "    RAGDocument(\n",
    "        document_id=f\"num-{i}\",\n",
    "        content=url,\n",
    "        mime_type=url_type,\n",
    "        metadata={},\n",
    "    )\n",
    "    for i, (url, url_type) in enumerate(urls)\n",
    "]\n",
    "\n",
    "logger.info(f\"Prepared {len(documents_ocp)} documents from URLs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "91652db1-0451-4ae6-9004-a07b50891b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://llama-stack-milvus-remote-service.rh-proposal-ai.svc.cluster.local:8321/v1/openai/v1/vector_stores \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Vector Stores: [VectorStore(id='vs_edd9686d-6e94-436d-8371-d12bed06e027', created_at=1762533012, file_counts=FileCounts(cancelled=0, completed=1, failed=0, in_progress=0, total=1), metadata={'provider_id': 'milvus-remote', 'provider_vector_db_id': 'vs_edd9686d-6e94-436d-8371-d12bed06e027'}, object='vector_store', status='completed', usage_bytes=0, expires_after=None, expires_at=None, last_active_at=1762533012, name='ocp_rh_vector_db'), VectorStore(id='vs_3d80ae85-456a-46b6-9314-2b86f502f323', created_at=1762532727, file_counts=FileCounts(cancelled=0, completed=2040, failed=0, in_progress=0, total=2040), metadata={'provider_id': 'milvus-remote', 'provider_vector_db_id': 'vs_3d80ae85-456a-46b6-9314-2b86f502f323'}, object='vector_store', status='completed', usage_bytes=0, expires_after=None, expires_at=None, last_active_at=1762532727, name='skus_rh_vector_db')]\n",
      "INFO:__main__:Vector Store id ocp: vs_edd9686d-6e94-436d-8371-d12bed06e027\n",
      "INFO:__main__:Vector Store id skus: vs_3d80ae85-456a-46b6-9314-2b86f502f323\n"
     ]
    }
   ],
   "source": [
    "vector_stores = client.vector_stores.list().data\n",
    "\n",
    "logger.info(f\"Vector Stores: {vector_stores}\")\n",
    "\n",
    "vector_db_skus_id = \"\"\n",
    "vector_db_ocp_id = \"\"\n",
    "\n",
    "for vector_store in vector_stores:\n",
    "    if (vector_store.name == vector_db_skus_name):\n",
    "        vector_db_skus_id = vector_store.id\n",
    "        logger.info(f\"Vector Store id skus: {vector_db_skus_id}\")\n",
    "    if (vector_store.name == vector_db_ocp_name):\n",
    "        vector_db_ocp_id = vector_store.id\n",
    "        logger.info(f\"Vector Store id ocp: {vector_db_ocp_id}\")\n",
    "\n",
    "delete_vector_stores = False\n",
    "\n",
    "if (delete_vector_stores):\n",
    "    # Delete thr vector store of SKUs\n",
    "    client.vector_stores.delete(\n",
    "        vector_store_id=vector_db_skus_id,\n",
    "    )\n",
    "\n",
    "    # Delete the vector store of Openshift\n",
    "    client.vector_stores.delete(\n",
    "        vector_store_id=vector_db_ocp_id,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63dfc59-4203-45bd-97dd-fef3fd9676bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch all registered models\n",
    "models = client.models.list()\n",
    "embedding_model = next(m for m in models if m.model_type == \"embedding\")\n",
    "embedding_model_id = embedding_model.identifier\n",
    "embedding_dimension = int(embedding_model.metadata[\"embedding_dimension\"])\n",
    "\n",
    "logger.info(f\"Documents ingested into RAG {vector_db_skus_name} successfully.\")\n",
    "\n",
    "vector_store_skus = client.vector_stores.create(\n",
    "    name=vector_db_skus_name,\n",
    "    embedding_model=embedding_model_id,\n",
    "    embedding_dimension=embedding_dimension,\n",
    "    provider_id=\"milvus-remote\",\n",
    "    metadata={\n",
    "        \"provider_vector_db_id\": vector_db_skus_id\n",
    "    }\n",
    ")\n",
    "\n",
    "logger.info(f\"The vector store ID created is: {vector_store_skus.id}\")\n",
    "\n",
    "# Insert documents to the vector database\n",
    "client.tool_runtime.rag_tool.insert(\n",
    "    documents=documents,\n",
    "    vector_db_id=vector_store_skus.id,\n",
    "    chunk_size_in_tokens=int(os.getenv(\"VECTOR_DB_CHUNK_SIZE\", 512)),\n",
    "    timeout=600,\n",
    ")\n",
    "\n",
    "logger.info(f\"Documents ingested into RAG {vector_db_skus_name} successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b17e34c-1b71-40f1-ad0d-c39eec1e125d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch all registered models\n",
    "models = client.models.list()\n",
    "embedding_model = next(m for m in models if m.model_type == \"embedding\")\n",
    "embedding_model_id = embedding_model.identifier\n",
    "embedding_dimension = int(embedding_model.metadata[\"embedding_dimension\"])\n",
    "\n",
    "vector_store_ocp = client.vector_stores.create(\n",
    "    name=vector_db_ocp_name,\n",
    "    embedding_model=embedding_model_id,\n",
    "    embedding_dimension=embedding_dimension,\n",
    "    provider_id=\"milvus-remote\",\n",
    ")\n",
    "\n",
    "logger.info(f\"The vector store ID created is: {vector_store_ocp.id}\")\n",
    "\n",
    "# Insert documents to the vector database\n",
    "client.tool_runtime.rag_tool.insert(\n",
    "    documents=documents_ocp,\n",
    "    vector_db_id=vector_store_ocp.id,\n",
    "    chunk_size_in_tokens=int(os.getenv(\"VECTOR_DB_CHUNK_SIZE\", 512)),\n",
    "    timeout=300,\n",
    ")\n",
    "\n",
    "logger.info(f\"Documents ingested into RAG {vector_db_ocp_name} successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3863f7-339d-4d4a-8965-00f2ad59f63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"List of Red Hat OpenShift SKUs\"\n",
    "\n",
    "# Execute the query against the vector database\n",
    "result = client.tool_runtime.rag_tool.query(\n",
    "    vector_db_ids=[vector_store_skus.id],\n",
    "    query_config={\"query\": query},\n",
    "    content=query,\n",
    ")\n",
    "\n",
    "logger.info(f\"RAG Query from {vector_db_skus_name} - Result: \\n{result.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071d177b-2daf-4b90-9f2a-6e14ee31e745",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is Red Hat OpenShift?\"\n",
    "\n",
    "# Execute the query against the vector database\n",
    "result = client.tool_runtime.rag_tool.query(\n",
    "    vector_db_ids=[vector_store_ocp.id],\n",
    "    query_config={\"query\": query},\n",
    "    content=query,\n",
    ")\n",
    "\n",
    "logger.info(f\"RAG Query from {vector_db_ocp_name} - Result: \\n{result.content}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
